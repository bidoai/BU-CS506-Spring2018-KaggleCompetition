{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things to do:\n",
    "#### 1. Read train.csv \n",
    "    Seperate train.csv into training data (data entries that have scores) and testing data (entries without scores, will also submit these predictions)\n",
    "    \n",
    "#### 2. seperate training data into y and x\n",
    "\n",
    "# Think of your model\n",
    "1. Linear Regression\n",
    "2. Sentiment analysis on Summary + Text, maybe even get emotions\n",
    "3. make product ID categorical?\n",
    "4. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import csv\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "'''from watson_developer_cloud import NaturalLanguageUnderstandingV1\n",
    "from watson_developer_cloud.natural_language_understanding_v1 \\\n",
    "  import Features, EntitiesOptions, KeywordsOptions, SentimentOptions'''\n",
    "from textblob import TextBlob as TB\n",
    "    \n",
    "def ReadData(filename):\n",
    "    f = open(filename, \"r\")\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)\n",
    "    i = 0\n",
    "    data = list(reader)\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    for i in range(len(data)):\n",
    "        if data[i][4] == \"\":\n",
    "            test_data += [data[i]]\n",
    "        else:\n",
    "            train_data += [data[i]]\n",
    "    return train_data, test_data, data      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"train.csv\"\n",
    "x = ReadData(filename)\n",
    "train = x[0]\n",
    "test = x[1]\n",
    "data = x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460804"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Products(data):\n",
    "    dic = {}\n",
    "    for entry in data:\n",
    "        if entry[3] not in dic:\n",
    "            dic[entry[3]] = 1\n",
    "        else:\n",
    "            dic[entry[3]] += 1\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FeatureVec(data):\n",
    "    '''\n",
    "    Output: adds a couple for columns to every entry\n",
    "    Think of what to add:\n",
    "        1. helpfulness numerator / helpfulness denominator \n",
    "        2. Sentiment of text data\n",
    "        3. Get emotions of text data?\n",
    "    '''\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        # append helpfulness numerator / helpfulness denominator\n",
    "        if int(data[i][0]) == 0:\n",
    "            data[i] += [0]\n",
    "        else:\n",
    "            data[i].append(float(data[i][1]) / float(data[i][0]))\n",
    "        temp = data[i][5] + \" \" + data[i][6]\n",
    "        temp = temp.strip()\n",
    "        textblob = TB(temp)\n",
    "        data[i] += [textblob.sentiment.polarity, textblob.sentiment.subjectivity]\n",
    "            \n",
    "        '''\n",
    "        Attempted to use Watson NLU to get sentiment scores and emotions of every summary + text\n",
    "        Unfortunately, I only have 30, 000 requests per month so this won't work.\n",
    "    \n",
    "        \n",
    "        response = nlu.analyze(\n",
    "                    text = temp,\n",
    "                    #html = article_html,\n",
    "                    features=Features(\n",
    "                        entities=EntitiesOptions(\n",
    "                          emotion=True,\n",
    "                          sentiment=True,\n",
    "                          limit=2),\n",
    "\n",
    "                        sentiment=SentOpt\n",
    "                    ))\n",
    "        # Use Watson Natural Language Understanding to get the emotions of the summary + text \n",
    "        # Also gets an overall sentiment score and positive/negative label\n",
    "        # add all these to our feature vectors\n",
    "        #print(temp)\n",
    "        #print(response)\n",
    "        if len(response['entities']) == 0:\n",
    "            sent_score = response['sentiment']['document']['score']\n",
    "            if response['sentiment']['document']['label'] == \"positive\":\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 0\n",
    "            anger = sent_score\n",
    "            disgust = sent_score\n",
    "            fear = sent_score\n",
    "            joy = sent_score\n",
    "            sadness = sent_score\n",
    "        else:\n",
    "            #print(response)\n",
    "            #print(\"-------------\")\n",
    "            if 'emotion' not in response[\"entities\"][0]:\n",
    "                sent = response[\"sentiment\"][\"document\"]\n",
    "                if sent['label'] == \"positive\":\n",
    "                    label = 1\n",
    "                else:\n",
    "                    label = 0\n",
    "                sent_score = sent[\"score\"]\n",
    "                anger = sent_score\n",
    "                disgust = sent_score\n",
    "                fear = sent_score\n",
    "                joy = sent_score\n",
    "                sadness = sent_score\n",
    "            else:\n",
    "                emotions = response['entities'][0]['emotion']\n",
    "                anger = emotions['anger']\n",
    "                disgust = emotions['disgust']\n",
    "                fear = emotions[\"fear\"]\n",
    "                joy = emotions[\"joy\"]\n",
    "                sadness = emotions[\"sadness\"]\n",
    "                sent = response['entities'][0]['sentiment']\n",
    "                if sent['label'] == 'positive':\n",
    "                    label = 1\n",
    "                else:\n",
    "                    label = 0\n",
    "                sent_score = sent['score']\n",
    "        data[i] += [anger, disgust, fear, joy, sadness, label, sent_score]'''\n",
    "    for entry in data:\n",
    "        if entry[4] == \"\":\n",
    "            entry[4] = 0\n",
    "    y_var = [int(entry[4]) for entry in data]\n",
    "    feature_vec = [ [int(entry[0]),int(entry[1])] + entry[-3:] for entry in data]\n",
    "    return y_var, feature_vec, data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = FeatureVec(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writes the augmented dataset to features.csv\n",
    "Write(X[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560804"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_var = X[1]\n",
    "y_var = X[0]\n",
    "X_col = sm.add_constant(x_var)\n",
    "model = sm.OLS(y_var, X_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.305</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.305</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>4.039e+04</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 05 May 2018</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:53:54</td>     <th>  Log-Likelihood:    </th> <td>-6.9484e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>460804</td>      <th>  AIC:               </th>  <td>1.390e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>460798</td>      <th>  BIC:               </th>  <td>1.390e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    3.6244</td> <td>    0.007</td> <td>  516.504</td> <td> 0.000</td> <td>    3.611</td> <td>    3.638</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.1524</td> <td>    0.001</td> <td> -175.213</td> <td> 0.000</td> <td>   -0.154</td> <td>   -0.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.1584</td> <td>    0.001</td> <td>  167.601</td> <td> 0.000</td> <td>    0.157</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0849</td> <td>    0.004</td> <td>   23.550</td> <td> 0.000</td> <td>    0.078</td> <td>    0.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    2.7351</td> <td>    0.007</td> <td>  367.932</td> <td> 0.000</td> <td>    2.721</td> <td>    2.750</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.2548</td> <td>    0.012</td> <td>  -20.631</td> <td> 0.000</td> <td>   -0.279</td> <td>   -0.231</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>58908.722</td> <th>  Durbin-Watson:     </th>  <td>   2.004</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>111019.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.829</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 4.742</td>   <th>  Cond. No.          </th>  <td>    102.</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.305\n",
       "Model:                            OLS   Adj. R-squared:                  0.305\n",
       "Method:                 Least Squares   F-statistic:                 4.039e+04\n",
       "Date:                Sat, 05 May 2018   Prob (F-statistic):               0.00\n",
       "Time:                        14:53:54   Log-Likelihood:            -6.9484e+05\n",
       "No. Observations:              460804   AIC:                         1.390e+06\n",
       "Df Residuals:                  460798   BIC:                         1.390e+06\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          3.6244      0.007    516.504      0.000       3.611       3.638\n",
       "x1            -0.1524      0.001   -175.213      0.000      -0.154      -0.151\n",
       "x2             0.1584      0.001    167.601      0.000       0.157       0.160\n",
       "x3             0.0849      0.004     23.550      0.000       0.078       0.092\n",
       "x4             2.7351      0.007    367.932      0.000       2.721       2.750\n",
       "x5            -0.2548      0.012    -20.631      0.000      -0.279      -0.231\n",
       "==============================================================================\n",
       "Omnibus:                    58908.722   Durbin-Watson:                   2.004\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           111019.023\n",
       "Skew:                          -0.829   Prob(JB):                         0.00\n",
       "Kurtosis:                       4.742   Cond. No.                         102.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.62438627, -0.15238043,  0.15838217,  0.08489057,  2.73511017,\n",
       "       -0.25475554])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = FeatureVec(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_col = sm.add_constant(X_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = results.predict(X_test_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_pred = [int(round(x)) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Text(data):\n",
    "    # Outputs a list of (summary + text)\n",
    "    return [entry[5] + \" \" + entry[6] for entry in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560804"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Write(data):\n",
    "    # Writes data to a csv file\n",
    "    with open(\"features.csv\", \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        header = [\"HelpfulnessDenominator\",\"HelpfulnessNumerator\",\"Id\",\"ProductId\",\"Score\",\n",
    "          \"Summary\", \"Text\", \"Time\", \"UserId\", \"HelpfulnessRatio\", \"SentimentPolarity\", \n",
    "         \"SentimentSubjectivity\"]\n",
    "        writer.writerow(header)\n",
    "        writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Results(int_predictions, test):\n",
    "    # get final prediction\n",
    "    results = []\n",
    "    for i in range(len(int_predictions)):\n",
    "        results += [[test[i][2], int_predictions[i]]]\n",
    "    with open(\"kaggle_results.csv\", \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        header = [\"Id\", \"Score\"]\n",
    "        writer.writerow(header)\n",
    "        writer.writerows(results)\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Results(int_pred, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def KfoldTest(data):\n",
    "    # Program that calculates the average MSE of model.fit() with 5-fold cross validation\n",
    "    # param data: data entries with their additional features added already\n",
    "    \n",
    "    # Holds MSE values from every fold\n",
    "    Predictions = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        \n",
    "        training_data = []\n",
    "        testing_data = []\n",
    "        # Create random sample of 400 training data, 100 teting data\n",
    "        training_index = random.sample(range(460804), 368000)\n",
    "        for data_index in range(460804):\n",
    "            if data_index in training_index:\n",
    "                training_data += [data[data_index]]\n",
    "            else:\n",
    "                testing_data += [data[data_index]]\n",
    "        \n",
    "        # Get dependent variable y\n",
    "        y_var = [int(entry[4]) for entry in training_data]\n",
    "        \n",
    "        # Get independent variable x\n",
    "        x_var = [[int(entry[0]),int(entry[1])] + entry[-3:] for entry in training_data]\n",
    "        \n",
    "        X = sm.add_constant(x_var)\n",
    "        model = sm.OLS(y_var, X)\n",
    "        \n",
    "        # Create regular model and regularized model\n",
    "        results = model.fit()\n",
    "        \n",
    "        # Get testing data dependent variable\n",
    "        testing_scores = [int(entry[4]) for entry in testingData]\n",
    "\n",
    "        # Get testing data independent variable\n",
    "        testing_X = [[int(entry[0]),int(entry[1])] + entry[-3:] for entry in data]            \n",
    "        testing_X = sm.add_constant(testing_X)\n",
    "        \n",
    "        # Make predictions with testing data according to model above\n",
    "        predictions = results.predict(testing_X)\n",
    "        \n",
    "        # Calculate MSEs\n",
    "        MSE = mean_squared_error(predictions, testing_scores)\n",
    "        \n",
    "        Predictions += [MSE]\n",
    "        \n",
    "    # Return average MSE over each fold\n",
    "    return sum(Predictions) / len(Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = KfoldTest(train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
